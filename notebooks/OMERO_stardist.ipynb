{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Stardist segmentation on 2D/3D/timelapse OMERO images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for Stardist segmentation. Some inspiration from the https://github.com/ome/omero-guide-cellprofiler/idr0002.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "# Import OMERO Python BlitzGateway\n",
    "import omero\n",
    "from omero.gateway import BlitzGateway\n",
    "import ezomero\n",
    "# Import Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import Python System Packages\n",
    "import os\n",
    "import tempfile\n",
    "import pandas\n",
    "import warnings\n",
    "\n",
    "#stardist related\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.plot import render_label\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imsave\n",
    "\n",
    "#load stardist model\n",
    "model = StarDist2D.from_pretrained('2D_versatile_fluo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Temp Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output_directory = os.path.normcase(tempfile.mkdtemp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup connection with OMERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "conn = BlitzGateway(host='localhost', username='root', passwd='omero', secure=True)\n",
    "print(conn.connect())\n",
    "conn.c.enableKeepAlive(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plate Name:  day7\n"
     ]
    }
   ],
   "source": [
    "datatype = \"plate\" # \"plate\", \"dataset\", \"image\"\n",
    "data_id = 52\n",
    "nucl_channel = 0\n",
    "\n",
    "#validate that data_id matches datatype\n",
    "if datatype == \"plate\":\n",
    "    plate = conn.getObject(\"Plate\", data_id)\n",
    "    print('Plate Name: ', plate.getName())\n",
    "elif datatype == \"dataset\":\n",
    "    dataset = conn.getObject(\"Dataset\", data_id)\n",
    "    print('Dataset Name: ', dataset.getName())\n",
    "elif datatype == \"image\":\n",
    "    image = conn.getObject(\"Image\", data_id)\n",
    "    print('Image Name: ', image.getName())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Stardist on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Tuple, Any, Optional\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tifffile import imsave\n",
    "import ezomero\n",
    "\n",
    "class ProcessImage:\n",
    "    \"\"\"Class to handle image processing and segmentation using StarDist.\"\"\"\n",
    "    \n",
    "    # Class constants\n",
    "    SEGMENTATION_NAMESPACE = \"stardist.segmentation\"\n",
    "    ROI_NAME = \"Stardist Nuclei\"\n",
    "    ROI_DESCRIPTION = \"Nuclei segmentation using Stardist\"\n",
    "    \n",
    "    def __init__(self, image: Any, conn: Any) -> None:\n",
    "        \"\"\"\n",
    "        Initialize ProcessImage instance.\n",
    "        \n",
    "        Args:\n",
    "            image: OMERO image object\n",
    "            conn: OMERO connection object\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If image or connection is invalid\n",
    "        \"\"\"\n",
    "        if not image or not conn:\n",
    "            raise ValueError(\"Image and connection must be provided\")\n",
    "            \n",
    "        self._image = image\n",
    "        self._conn = conn\n",
    "        self._pixels = image.getPrimaryPixels()\n",
    "        self._size_c = image.getSizeC()\n",
    "        self._size_z = image.getSizeZ()\n",
    "        self._labels = None\n",
    "        self._polygons = None\n",
    "        \n",
    "        # Set up logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    @property\n",
    "    def labels(self) -> np.ndarray:\n",
    "        \"\"\"Get segmentation labels.\"\"\"\n",
    "        if self._labels is None:\n",
    "            raise ValueError(\"Segmentation has not been performed yet\")\n",
    "        return self._labels\n",
    "        \n",
    "    def segment_nuclei(self, nucl_channel: int) -> None:\n",
    "        \"\"\"\n",
    "        Segment nuclei in the specified channel.\n",
    "        \n",
    "        Args:\n",
    "            nucl_channel: Channel number for nuclear staining\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If channel number is invalid\n",
    "        \"\"\"\n",
    "        if not 0 <= nucl_channel < self._size_c:\n",
    "            raise ValueError(f\"Invalid channel number: {nucl_channel}\")\n",
    "            \n",
    "        try:\n",
    "            if self._size_z > 1:\n",
    "                self._segment_3d_image(nucl_channel)\n",
    "            else:\n",
    "                self._segment_2d_image(nucl_channel)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Segmentation failed: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def _segment_3d_image(self, channel: int) -> None:\n",
    "        \"\"\"Handle 3D image segmentation.\"\"\"\n",
    "        planes = [self._pixels.getPlane(z, channel, 0) for z in range(self._size_z)]\n",
    "        labels_polygons = [self._segment_slice(plane) for plane in planes]\n",
    "        self._labels, self._polygons = zip(*labels_polygons)\n",
    "        \n",
    "    def _segment_2d_image(self, channel: int) -> None:\n",
    "        \"\"\"Handle 2D image segmentation.\"\"\"\n",
    "        plane = self._pixels.getPlane(0, channel, 0)\n",
    "        labels_polygons = self._segment_slice(plane)\n",
    "        self._labels, self._polygons = zip(*[labels_polygons])\n",
    "        \n",
    "    def _segment_slice(self, plane: np.ndarray) -> Tuple[np.ndarray, Any]:\n",
    "        \"\"\"\n",
    "        Segment a single image plane.\n",
    "        \n",
    "        Args:\n",
    "            plane: 2D numpy array representing image plane\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (labels, polygons)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            img = normalize(plane)\n",
    "            return model.predict_instances(img)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Slice segmentation failed: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def save_segmentation_to_omero_as_new_image(self, new_img_name: str, desc: str) -> None:\n",
    "        \"\"\"Save segmentation as new OMERO image.\"\"\"\n",
    "        try:\n",
    "            new_img = self._conn.createImageFromNumpySeq(\n",
    "                iter(self.labels), \n",
    "                new_img_name, \n",
    "                self._size_z, \n",
    "                1, \n",
    "                1, \n",
    "                description=desc, \n",
    "                dataset=self._image.getParent()\n",
    "            )\n",
    "            self.logger.info(f'Created new Image:{new_img.getId()} Name:\"{new_img.getName()}\"')\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to save new image: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def save_segmentation_to_omero_as_attach(self, tmp_dir: str, desc: str) -> None:\n",
    "        \"\"\"Save segmentation as OMERO attachment.\"\"\"\n",
    "        tmp_path = Path(tmp_dir)\n",
    "        if not tmp_path.exists():\n",
    "            tmp_path.mkdir(parents=True)\n",
    "            \n",
    "        tif_file = tmp_path / f\"{self._image.getName()}_segmentation.tif\"\n",
    "        \n",
    "        try:\n",
    "            imsave(tif_file, self.labels)\n",
    "            file_annotation_id = ezomero.post_file_annotation(\n",
    "                self._conn,\n",
    "                str(tif_file),\n",
    "                ns=self.SEGMENTATION_NAMESPACE,\n",
    "                object_type=\"Image\",\n",
    "                object_id=self._image.getId(),\n",
    "                description=desc\n",
    "            )\n",
    "            self.logger.info(f'File annotation ID: {file_annotation_id}')\n",
    "        finally:\n",
    "            if tif_file.exists():\n",
    "                tif_file.unlink()\n",
    "    def _create_polygon_shapes(self) -> List[dict]:\n",
    "        \"\"\"Create polygon shapes from segmentation results.\"\"\"\n",
    "        all_polygons = []\n",
    "        for z, polygons in enumerate(self._polygons):\n",
    "            coords_array = polygons['coord']\n",
    "            # Process each contour in the coordinates array\n",
    "            for contour_idx in range(coords_array.shape[0]):\n",
    "                try:\n",
    "                    # Extract x,y coordinates for current contour\n",
    "                    xy_coords = coords_array[contour_idx]\n",
    "                    # x and y coordinates are flipped from StarDist output\n",
    "                    points = [(float(y), float(x)) for x, y in zip(xy_coords[0], xy_coords[1])]\n",
    "                    \n",
    "                    ezomero_polygon = ezomero.rois.Polygon(\n",
    "                        points=points,\n",
    "                        z=z,\n",
    "                        c=None,\n",
    "                        t=None,\n",
    "                        label=\"nuclei\",\n",
    "                        fill_color=None,\n",
    "                        stroke_color=None,\n",
    "                        stroke_width=None\n",
    "                    )\n",
    "                    all_polygons.append(ezomero_polygon)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing contour {contour_idx} at z={z}: {e}\")\n",
    "                    continue\n",
    "        return all_polygons\n",
    "\n",
    "    def save_segmentation_to_omero_as_roi(self) -> None:\n",
    "        \"\"\"Save segmentation as OMERO ROIs.\"\"\"\n",
    "        if not self._polygons:\n",
    "            raise ValueError(\"No polygons available - run segmentation first\")\n",
    "            \n",
    "        all_polygons = self._create_polygon_shapes()\n",
    "        \n",
    "        if all_polygons:\n",
    "            try:\n",
    "                roi_id = ezomero.post_roi(\n",
    "                    conn=self._conn,\n",
    "                    image_id=self._image.getId(),\n",
    "                    shapes=all_polygons,\n",
    "                    name=self.ROI_NAME,\n",
    "                    description=self.ROI_DESCRIPTION\n",
    "                )\n",
    "                self.logger.info(f\"Created ROI with ID: {roi_id}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error creating ROI: {str(e)}\")\n",
    "                raise\n",
    "        else:\n",
    "            self.logger.warning(\"No valid polygons were created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclesperanto_prototype as cle\n",
    "import pandas as pd\n",
    "\n",
    "def measure_intensity(pixels, labels, size_z, size_c):\n",
    "    all_statistics = []\n",
    "    if size_z > 1:\n",
    "        for z, label in zip(range(size_z), labels):\n",
    "            for c in range(size_c):\n",
    "                statistics = cle.statistics_of_labelled_pixels(pixels.getPlane(z, c, 0), label)\n",
    "                statistics = pd.DataFrame(statistics)\n",
    "                statistics['z'] = z\n",
    "                statistics['channel'] = c\n",
    "                all_statistics.append(statistics)\n",
    "    else:\n",
    "        statistics = cle.statistics_of_labelled_pixels(pixels.getPlane(1, 0, 0), labels)\n",
    "        statistics['z'] = 0\n",
    "        all_statistics.append(statistics)\n",
    "    \n",
    "    # Concatenate all statistics into a single DataFrame\n",
    "    all_statistics_df = pd.concat(all_statistics, ignore_index=True)\n",
    "    \n",
    "    return all_statistics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well: 1/72 row: 0 column: 0\n",
      "Field: 0\n"
     ]
    }
   ],
   "source": [
    "#TODO extend to handle multiple channels,timepoints\n",
    "#TODO measure the intensity of the segmented nuclei in the other channels\n",
    "#TODO attach those results as a table to the original image in OMERO\n",
    "\n",
    "if datatype == \"plate\":\n",
    "    wells = list(plate.listChildren())\n",
    "    # use the first 3 wells only\n",
    "    #wells = wells[0:3] # for testing\n",
    "    well_count = len(wells)\n",
    "    for count, well in enumerate(wells):\n",
    "            print('Well: %s/%s' % (count + 1, well_count), 'row:', well.row, 'column:', well.column)\n",
    "            # Load a single Image per Well TODO load all images for a well if there are multiple\n",
    "            fields = well.countWellSample()\n",
    "            for field in range(fields):\n",
    "                print('Field:', field)\n",
    "                image = well.getImage(field)\n",
    "                #save stack back to OMERO same project only add _nucleisegmentation to the name\n",
    "                new_img_name = image.getName() + \"_nucleisegmentation\"\n",
    "                desc = \"Stardist nuclei segmentation\"\n",
    "                img = ProcessImage(image, conn)\n",
    "                img.segment_nuclei(nucl_channel)\n",
    "                img.save_segmentation_to_omero_as_attach(new_output_directory,desc)\n",
    "                img.save_segmentation_to_omero_as_new_image(new_img_name,desc)\n",
    "                img.save_segmentation_to_omero_as_roi()\n",
    "\n",
    "                all_statistics_df = measure_intensity(img._pixels, img._labels, img._size_z, img._size_c)\n",
    "                tabelid = ezomero.post_table(conn, object_type=\"Image\", object_id=image.getId(), table = all_statistics_df,title=\"Nuclei_measurements\")\n",
    "                print('Created table ID:', tabelid)\n",
    "\n",
    "            \n",
    "elif datatype == \"dataset\":\n",
    "    images = list(dataset.listChildren())\n",
    "    # use the first 3 images only\n",
    "    images = images[0:3]\n",
    "    image_count = len(images)\n",
    "    for count in range(image_count):\n",
    "        image = well.getImage(count)\n",
    "        #save stack back to OMERO same project only add _nucleisegmentation to the name\n",
    "        new_img_name = image.getName() + \"_nucleisegmentation\"\n",
    "        desc = \"Stardist nuclei segmentation\"\n",
    "        img = ProcessImage(image, conn)\n",
    "        img.segment_nuclei(nucl_channel)\n",
    "        img.save_segmentation_to_omero_as_attach(new_output_directory,desc)\n",
    "        img.save_segmentation_to_omero_as_new_image(desc)\n",
    "        img.save_segmentation_to_omero_as_roi()\n",
    "\n",
    "        all_statistics_df = measure_intensity(img.pixels, img.labels, img.size_z, img.size_c)\n",
    "        tabelid = ezomero.post_table(conn, object_type=\"Image\", object_id=image.getId(), table = all_statistics_df,title=\"Nuclei_measurements\")\n",
    "        print('Created table ID:', tabelid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omero-guide-cellprofiler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
